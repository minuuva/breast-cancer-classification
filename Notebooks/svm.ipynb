{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39364faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "# handle warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f93a3",
   "metadata": {},
   "source": [
    "### 1. Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb58d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Dimensions:\n",
      "X_train: (455, 30)\n",
      "y_train: (455,)\n",
      "------------------------------------------------------------\n",
      "Target Distribution:\n",
      "Benign (0): 285 samples (62.6%)\n",
      "Malignant (1): 170 samples (37.4%)\n",
      "Total: 455 samples\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# loading the train set\n",
    "train_df = pd.read_csv('../Data/breast_cancer_trainset.csv')\n",
    "\n",
    "X_train = train_df.drop(columns=['diagnosis'])\n",
    "y_train = train_df['diagnosis']\n",
    "\n",
    "# Data dimensions\n",
    "print(\"Data Dimensions:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "# Target distribution\n",
    "print(\"-\"*60)\n",
    "print(\"Target Distribution:\")\n",
    "print(f\"Benign (0): {(y_train==0).sum()} samples ({(y_train==0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Malignant (1): {(y_train==1).sum()} samples ({(y_train==1).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Total: {len(y_train)} samples\")\n",
    "print(\"-\"*60)\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435774e",
   "metadata": {},
   "source": [
    "### 2. Building a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00fc3d",
   "metadata": {},
   "source": [
    "We used a pipeline to avoid any data leakage during the preprocessing steps. This ensures stadard scaler is called on the training set in each cross validation fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf57755",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(probability=True))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23048d5",
   "metadata": {},
   "source": [
    "### 3. Hypertuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15321c7b",
   "metadata": {},
   "source": [
    "We used GridSearchCV with 5-fold cross validation to find the most optimal hyperparameters for our SVM model. GridSearchCV automatically splits the training data into folds, trains the model on different hyperparameter combinations, and evaluates performance using cross-validation. \n",
    "\n",
    "In the range of parameters, we included svm__C, which is a regularization parameter that controls the trade off between a smooth decision boundary and classifying correctly. We also included svm__kernel to test the linear, rbf, and polynomial kernels. svm__gamma is the kernel coefficient for rbf and polynomial, and controls the influence of a single training example. Lastly, svm__degree is the degree of the polynomial kernel function, which we set to test values of 2 and 3. \n",
    "\n",
    "We chose to optimize for recall as the scoring metric to minimize false negatives. In this use case, false negatives would mean missing a cancer diagnosis when the patient has cancer, which is critical in medical applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145eda1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best CV accuracy: 0.9588235294117649\n",
      "Best parameters: {'svm__C': 1, 'svm__degree': 2, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# parameters for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"svm__C\": [0.1, 1, 10, 50], \n",
    "    \"svm__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "    \"svm__degree\": [2, 3], # only for poly kernel\n",
    "}\n",
    "\n",
    "# perform gridsearch\n",
    "grid = GridSearchCV(\n",
    "    estimator=svm_pipeline,\n",
    "    param_grid = param_grid, \n",
    "    cv = 5, \n",
    "    scoring = 'recall', \n",
    "    n_jobs = -1,\n",
    "    verbose = 2\n",
    ")\n",
    "# fit model\n",
    "grid.fit(X_train, y_train)\n",
    "# best model\n",
    "print(\"Best CV accuracy:\", grid.best_score_)\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff386c21",
   "metadata": {},
   "source": [
    "### 4. Evaluating Model Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f5972",
   "metadata": {},
   "source": [
    "After performing gridsearch, we found the best model, based on highest average recall score across all folds, used the radial basis function kernel with C=1, gamma = scale, and degree of 2. This gave us a CV recall score of 0.9588. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f15557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BEST MODEL FROM GRIDSEARCHCV\n",
      "======================================================================\n",
      "\n",
      "Best Hyperparameters:\n",
      "  svm__C: 1\n",
      "  svm__degree: 2\n",
      "  svm__gamma: scale\n",
      "  svm__kernel: rbf\n",
      "\n",
      "Best Cross-Validation Recall Score: 0.9588\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Top 5 Hyperparameter Combinations (by Recall):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Rank 1:\n",
      "  Recall: 0.9588 (±0.0300)\n",
      "  Params: {'svm__C': 1, 'svm__degree': 2, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "\n",
      "Rank 2:\n",
      "  Recall: 0.9588 (±0.0300)\n",
      "  Params: {'svm__C': 1, 'svm__degree': 2, 'svm__gamma': 'auto', 'svm__kernel': 'rbf'}\n",
      "\n",
      "Rank 3:\n",
      "  Recall: 0.9588 (±0.0300)\n",
      "  Params: {'svm__C': 1, 'svm__degree': 3, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "\n",
      "Rank 4:\n",
      "  Recall: 0.9588 (±0.0300)\n",
      "  Params: {'svm__C': 1, 'svm__degree': 3, 'svm__gamma': 'auto', 'svm__kernel': 'rbf'}\n",
      "\n",
      "Rank 5:\n",
      "  Recall: 0.9588 (±0.0399)\n",
      "  Params: {'svm__C': 10, 'svm__degree': 2, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "\n",
      "======================================================================\n",
      "Model is ready for final test set evaluation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "svm_best_model = grid.best_estimator_\n",
    "\n",
    "# Display best hyperparameters\n",
    "print(\"=\" * 70)\n",
    "print(\"BEST MODEL FROM GRIDSEARCHCV\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in grid.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest Cross-Validation Recall Score: {grid.best_score_:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Display CV results summary\n",
    "cv_results_df = pd.DataFrame(grid.cv_results_)\n",
    "top_5_models = cv_results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "print(\"\\nTop 5 Hyperparameter Combinations (by Recall):\")\n",
    "print(\"-\" * 70)\n",
    "for idx, row in top_5_models.iterrows():\n",
    "    print(f\"\\nRank {top_5_models.index.get_loc(idx) + 1}:\")\n",
    "    print(f\"  Recall: {row['mean_test_score']:.4f} (±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Params: {row['params']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Model is ready for final test set evaluation.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
